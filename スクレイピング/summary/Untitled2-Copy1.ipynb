{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96ede5a3-585b-4e75-9bf1-42ab330b648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def text_summary(sentence, errormessage):\n",
    "    # 抽出文章数は入力文章数の2分の1\n",
    "    count = sentence.count('。')\n",
    "    count = round(count / 2)\n",
    "    if count < 1:\n",
    "        count = 1\n",
    "\n",
    "    # WebAPIにパラメータをPOSTで渡す\n",
    "    url = 'https://api.a3rt.recruit.co.jp/text_summarization/v1'\n",
    "    apikey = 'DZZkH17tdljiJjcI6DwY5ToVTWWGxwqc'\n",
    "    \n",
    "    post_data = {\n",
    "        'apikey': apikey,\n",
    "        'sentences': sentence,\n",
    "        'linenumber': count,\n",
    "        'separation': '。'\n",
    "    }\n",
    "\n",
    "    # 要約\n",
    "    res = ''\n",
    "    errormessage[0] = ''\n",
    "    response = requests.post(url, data=post_data)\n",
    "    json_data = response.json()\n",
    "\n",
    "    # エラーチェック\n",
    "    if not json_data:\n",
    "        res = False\n",
    "        errormessage[0] = 'WebAPIが停止'\n",
    "    elif 'status' in json_data and json_data['status'] == 0:\n",
    "        if 'summary' in json_data and json_data['summary']:\n",
    "            for ss in json_data['summary']:\n",
    "                res += str(ss) + '。'\n",
    "        else:\n",
    "            res = False\n",
    "            errormessage[0] = '要約データが存在しません'\n",
    "    else:\n",
    "        res = False\n",
    "        errormessage[0] = json_data['message']\n",
    "\n",
    "    return res\n",
    "\n",
    "summary_sentence = ''\n",
    "for i, sentence in enumerate(split_sentence):\n",
    "    sentence = sentence.replace(' ', '')\n",
    "    result = text_summary(sentence, errormessage)\n",
    "    try:\n",
    "        summary_sentence += result\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ceb388c9-adef-4926-86b1-e2dfc16e0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'労働基準法41条において、事業の種類にかかわらず、監督もしくは管理の地位にある者または機密の事務を取り扱う者（＝「管理監督者」という）については労働時間、休憩及び休日に関する規定は適用しないと定められています。これにより、管理監督者に対しては残業という概念が適用されないため、残業代の支払いは不要とされています。イメージされる「管理職」と労働基準法上の「管理監督者」には大きな違いがあります。管理職であれば必ず管理監督者に該当するわけではなく、労働実態を見て「職務内容」「責任と権限」「勤務態様」「待遇」によって判断されます。のであること（時を選ばず経営上の判断や対応が要請されること）（4）賃金等について、その地位にふさわしい待遇がなされていること管理職の肩書ではあるものの、実際の働き方や待遇を見ると管理監督者とはいえない「名ばかり管理職」に対しては、会社は残業代を支払わなければなりません。例えば「課長」や「マネージャー」などは、肩書や立場的には確かに管理職ではありますが、経営者と一体の立場であったり、経営上の判断を委ねられたりということは、一般的にはまれなケースだと考えられます。'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c2b7dde-52d0-42a6-9210-51fc87ccf2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'苦労してせっかく管理職になったのに、昇格したら残業代が払われなくなって結局手取りが減ってしまったという経験がある人もいるのではないでしょうか。管理職になると残業代の支給がなくなる会社は少なくないですが、本来は残業代をもらうべきケースであることは意外と多いものです。 本記事では管理職になると残業代が支払われなくなる理由と、残業代が支払われるべきケースについて解説します。労働基準法41条において、事業の種類にかかわらず、監督もしくは管理の地位にある者または機密の事務を取り扱う者（＝「管理監督者」という）については労働時間、休憩及び休日に関する規定は適用しないと定められています。 これにより、管理監督者に対しては残業という概念が適用されないため、残業代の支払いは不要とされています。ただし、一般的にイメージされる「管理職」と労働基準法上の「管理監督者」には大きな違いがあります。 管理職であれば必ず管理監督者に該当するわけではなく、労働実態を見て「職務内容」「責任と権限」「勤務態様」「待遇」によって判断されます。 残業代の支給が不要な労働基準法上の管理監督者とするためには、以下の4つの要件をすべて満たす必要があります。 （1）労働時間、休憩、休日等に関する、労働基準法上の規制の枠を超えて活動せざるを得ない重要な職務内容であること（経営者と一体の立場であること） （2）労働時間、休憩、休日等に関する、労働基準法上の規制の枠を超えて活動せざるを得ない重要な責任と権限を有していること（経営者から重要な責任と権限を委ねられていること） （3）現実の勤務態様も、労働時間等の規制になじまないようなものであること（時を選ばず経営上の判断や対応が要請されること） （4）賃金等について、その地位にふさわしい待遇がなされていること 管理職の肩書ではあるものの、実際の働き方や待遇を見ると管理監督者とはいえない「名ばかり管理職」に対しては、会社は残業代を支払わなければなりません。 例えば「課長」や「マネージャー」などは、肩書や立場的には確かに管理職ではありますが、経営者と一体の立場であったり、経営上の判断を委ねられたりということは、一般的にはまれなケースだと考えられます。 待遇面からみても、課長やマネージャーは数万円の手当のみというケースが多いのではないでしょうか。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00770bef-9074-4cdd-93e6-2e4a1babfcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ニュースの本文を区切る\n",
    "def length_decision(sentence):\n",
    "    if (len(sentence) > 350):\n",
    "        split_sentence = []\n",
    "        count = round(len(sentence) / 350)\n",
    "        for i in range(count+1):\n",
    "            start = i * 350\n",
    "            stop = (i + 1) * 350\n",
    "            split_sentence.append(sentence[start:stop])\n",
    "    return split_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "341f11a3-b72e-44ed-997a-6fd5d57e21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sentence = length_decision(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9da4a361-3e75-4e5b-8ebf-580e028d7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "苦労してせっかく管理職になったのに、昇格したら残業代が払われなくなって結局手取りが減ってしまったという経験がある人もいるのではないでしょうか。管理職になると残業代の支給がなくなる会社は少なくないですが、本来は残業代をもらうべきケースであることは意外と多いものです。 本記事では管理職になると残業代が支払われなくなる理由と、残業代が支払われるべきケースについて解説します。労働基準法41条において、事業の種類にかかわらず、監督もしくは管理の地位にある者または機密の事務を取り扱う者（＝「管理監督者」という）については労働時間、休憩及び休日に関する規定は適用しないと定められています。 これにより、管理監督者に対しては残業という概念が適用されないため、残業代の支払いは不要とされています。ただし、一般的に\n",
      "--------------------------\n",
      "350\n",
      "イメージされる「管理職」と労働基準法上の「管理監督者」には大きな違いがあります。 管理職であれば必ず管理監督者に該当するわけではなく、労働実態を見て「職務内容」「責任と権限」「勤務態様」「待遇」によって判断されます。 残業代の支給が不要な労働基準法上の管理監督者とするためには、以下の4つの要件をすべて満たす必要があります。 （1）労働時間、休憩、休日等に関する、労働基準法上の規制の枠を超えて活動せざるを得ない重要な職務内容であること（経営者と一体の立場であること） （2）労働時間、休憩、休日等に関する、労働基準法上の規制の枠を超えて活動せざるを得ない重要な責任と権限を有していること（経営者から重要な責任と権限を委ねられていること） （3）現実の勤務態様も、労働時間等の規制になじまないようなも\n",
      "--------------------------\n",
      "283\n",
      "のであること（時を選ばず経営上の判断や対応が要請されること） （4）賃金等について、その地位にふさわしい待遇がなされていること 管理職の肩書ではあるものの、実際の働き方や待遇を見ると管理監督者とはいえない「名ばかり管理職」に対しては、会社は残業代を支払わなければなりません。 例えば「課長」や「マネージャー」などは、肩書や立場的には確かに管理職ではありますが、経営者と一体の立場であったり、経営上の判断を委ねられたりということは、一般的にはまれなケースだと考えられます。 待遇面からみても、課長やマネージャーは数万円の手当のみというケースが多いのではないでしょうか。\n",
      "--------------------------\n",
      "0\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for a, i in enumerate(split_sentence):\n",
    "    print(len(split_sentence[a]))\n",
    "    print(i)\n",
    "    print('--------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895de698-6bcd-499b-9fe9-d8e306cd6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "#ヤフーニュースの情報を取得\n",
    "def yahoo_news_scraping(topic):\n",
    "    url = 'https://news.yahoo.co.jp/'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    \n",
    "    list_item = soup.find_all('li')\n",
    "    #もしかしたらエラーの原因になるかも\n",
    "    list_item = list_item[12:21]\n",
    "    \n",
    "    # <a>要素からトピックを取得\n",
    "    a_contents = [li.a for li in list_item]\n",
    "    \n",
    "    articles_dict = []\n",
    "    topic = topic \n",
    "    #トピックのURL取得\n",
    "    for i, a_content in enumerate(a_contents):\n",
    "        if topic in a_content.text:\n",
    "            categories_num = i\n",
    "    \n",
    "    a_content = a_contents[categories_num]\n",
    "    \n",
    "    topic_url = a_content['href']\n",
    "    URL = url + topic_url\n",
    "    \n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    #クラス名が変わるので注意！！\n",
    "    elements = soup.select('.sc-fXazdy.UjHkE')\n",
    "    \n",
    "    elements = elements[:5]\n",
    "    \n",
    "    news_urls = []\n",
    "    news_titles = []\n",
    "    #ニュースのURLとタイトルを取得\n",
    "    for element in elements:\n",
    "        url = element.a['href']\n",
    "        title = element.text[1:]\n",
    "        news_urls.append(url)\n",
    "        news_titles.append(title)\n",
    "            \n",
    "    news_text = []\n",
    "    #ニュースの本文を取得\n",
    "    for news_url in news_urls:\n",
    "        r = requests.get(news_url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        #クラス名が変わるので注意！！ \n",
    "        elements = soup.select('.sc-iMCRTP.ePfheF.yjSlinkDirectlink.highLightSearchTarget')\n",
    "    \n",
    "        text = \"\"\n",
    "    \n",
    "        #ニュース記事の本文が配列で区切られていた場合\n",
    "        for i in range(0, 8):\n",
    "            try:\n",
    "                if (i == 0):\n",
    "                    text = elements[0].text\n",
    "                else:\n",
    "                    text += elements[i].text\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        #ページが1つだけのとき、エラーが出るため\n",
    "        try:\n",
    "            #クラス名が変わるので注意！！ （取得例：２ページ)\n",
    "            page_element = soup.select('.sc-cpUASM.bqNXll')\n",
    "            page = page_element[0].text         \n",
    "            page_str = ''.join(filter(str.isdigit, page))\n",
    "            page_num = int(page_str)\n",
    "        except:\n",
    "            page_num = 1\n",
    "            \n",
    "        #ページ数が複数のとき、ページ遷移し本文を取得\n",
    "        if (page_num > 1):\n",
    "            for i in range(2, page_num + 1):\n",
    "                news_url_page = news_url + \"?page=\" + str(page_num)\n",
    "                r = requests.get(news_url_page)\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                #クラス名が変わるので注意！！ \n",
    "                elements = soup.select('.sc-iMCRTP.ePfheF.yjSlinkDirectlink.highLightSearchTargett')\n",
    "                #ニュース記事の本文が配列で区切られていた場合\n",
    "                for i in range(0, 8):\n",
    "                    try:\n",
    "                        text += elements[i].text\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "        news_text.append(text)\n",
    "    \n",
    "        time.sleep(0.5)\n",
    "\n",
    "    articles = []\n",
    "    for url, title, text in zip(news_urls, news_titles, news_text):\n",
    "        article = {\n",
    "            \"title\" : title,\n",
    "            \"URL\" : url,\n",
    "            \"text\" : text\n",
    "        }\n",
    "        articles.append(article)\n",
    "\n",
    "    return articles\n",
    "\n",
    "#CNNニュースの情報を取得\n",
    "def cnn_news_scraping(topic):\n",
    "    url = 'https://www.cnn.co.jp'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    #クラス名が変わるので注意！！\n",
    "    elements = soup.select('.pg-container li a')\n",
    "    elements = elements[6:11] + [elements[14], elements[16]]\n",
    "    \n",
    "    topic = topic\n",
    "    #トピックのURL取得\n",
    "    for i, element in enumerate(elements):\n",
    "        if topic in element.text:\n",
    "            categories_num = i\n",
    "    \n",
    "    element = elements[categories_num]\n",
    "    \n",
    "    topic_url = element['href']\n",
    "    URL = url + topic_url\n",
    "    \n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    #クラス名が変わるので注意！！\n",
    "    elements = soup.select('.cd a')\n",
    "    \n",
    "    elements = elements[:3]\n",
    "    \n",
    "    news_urls = []\n",
    "    news_titles = []\n",
    "    #ニュースのURLとタイトルを取得\n",
    "    for element in elements:\n",
    "        news_url =  url + element['href']\n",
    "        news_title = element.text\n",
    "    \n",
    "        news_urls.append(news_url)\n",
    "        news_titles.append(news_title)\n",
    "    \n",
    "    news_text = []\n",
    "    #ニュースの本文を取得\n",
    "    for i, news_url in enumerate(news_urls):\n",
    "        text = \"\"\n",
    "        \n",
    "        for j in range(1, 7):\n",
    "            num = str(j)\n",
    "            page = '-' + num + '.html'    \n",
    "            # 文字列の置換を行い新しいURLを生成\n",
    "            news_url_page = news_urls[i].replace('.html', page)\n",
    "    \n",
    "            #ページ数が複数のとき、ページ遷移し本文を取得\n",
    "            response = requests.get(news_url_page)\n",
    "    \n",
    "            # レスポンスのステータスコードを確認\n",
    "            if response.status_code != 404: \n",
    "                r = requests.get(news_url_page)\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                #クラス名が変わるので注意！！ \n",
    "                elements = soup.find(id = 'leaf-body')\n",
    "                text += elements.text\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "        news_text.append(text)\n",
    "\n",
    "    articles = []\n",
    "    for url, title, text in zip(news_urls, news_titles, news_text):\n",
    "        article = {\n",
    "            \"title\" : title,\n",
    "            \"URL\" : url,\n",
    "            \"text\" : text\n",
    "        }\n",
    "        articles.append(article)\n",
    "\n",
    "    return articles\n",
    "\n",
    "#データを整える\n",
    "def clean_data(articles):\n",
    "    for i in range(len(articles)):\n",
    "        articles[i]['title'] = articles[i]['title'].replace('\\u3000', '') \n",
    "        articles[i]['title'] = articles[i]['title'].lstrip('0123456789')\n",
    "        articles[i]['text'] = articles[i]['text'].replace('\\u3000', '')\n",
    "        articles[i]['text'] = articles[i]['text'].replace('\\n', '')\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa165d0e-b96b-414f-b26c-11979b3bf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict = yahoo_news_scraping('経済')\n",
    "articles = clean_data(articles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae30612-32b2-4961-8f19-73f2ebe2c11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
